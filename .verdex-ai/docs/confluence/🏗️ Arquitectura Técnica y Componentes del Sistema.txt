ğŸ—ï¸ ARQUITECTURA TÃ‰CNICA Y COMPONENTES DEL SISTEMA
ğŸ“‹ Resumen de la Arquitectura
El Asistente Voz Realtime estÃ¡ construido sobre una arquitectura de microservicios containerizada que permite escalabilidad, mantenibilidad y flexibilidad en el desarrollo. La soluciÃ³n integra mÃºltiples tecnologÃ­as de vanguardia para crear un flujo completo desde la captura de audio hasta la ejecuciÃ³n de acciones automatizadas.

ğŸ¯ Diagrama de Arquitectura General


graph TB
    subgraph "Cliente MÃ³vil"
        A[ğŸ“± Flutter App]
        A1[ğŸ¤ Audio Recorder]
        A2[ğŸ“¡ MQTT Client]
        A3[ğŸ” Auth Module]
        A4[ğŸ“Š UI Components]
    end
    subgraph "Backend Services"
        B[ğŸ”§ FastAPI Gateway]
        C[ğŸ¯ Whisper Service]
        D[ğŸ§  NLP Processor]
        E[ğŸ“Š MongoDB]
        F[ğŸ“¡ EMQX Broker]
        G[âš¡ n8n Workflows]
    end
    subgraph "Integraciones Externas"
        H[ğŸ”— Atlassian Rovo]
        I[ğŸ“… Google Calendar]
        J[ğŸ”Œ MCPs/Webhooks]
        K[ğŸ¤– OpenAI API]
    end
    A1 -->|Audio Upload| B
    B -->|Transcription| C
    C -->|Text| D
    D -->|Metadata| E
    D -->|Trigger| G
    G -->|Actions| H
    G -->|Events| I
    G -->|Custom| J
    C -->|API Calls| K
    G -->|Notifications| F
    F -->|Real-time| A2
    B -->|Auth| A3
    E -->|Data| A4
ğŸ”§ Componentes Principales
ğŸ“± 1. AplicaciÃ³n Flutter (Cliente MÃ³vil)
Responsabilidades:
ğŸ¤ Captura de audio hasta 5 minutos

ğŸ”Š DetecciÃ³n de actividad de voz (VAD)

ğŸ“¤ EnvÃ­o seguro al backend vÃ­a HTTPS

ğŸ“¡ Cliente MQTT para notificaciones en tiempo real

ğŸ¨ Interfaz de usuario moderna y responsiva

ğŸ” AutenticaciÃ³n y gestiÃ³n de sesiones

TecnologÃ­as:
Framework: Flutter 3.x (Dart)

Audio: flutter_sound package

MQTT: mqtt_client package

HTTP: dio package para API calls

State Management: Provider/Riverpod

Storage: shared_preferences + hive

Estructura de Archivos:


lib/
â”œâ”€â”€ main.dart
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ audio_recording.dart
â”‚   â””â”€â”€ config_model.dart
â”œâ”€â”€ providers/
â”‚   â””â”€â”€ audio_provider.dart
â”œâ”€â”€ screens/
â”‚   â””â”€â”€ home_screen.dart
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ audio_service.dart
â”‚   â”œâ”€â”€ upload_service.dart
â”‚   â”œâ”€â”€ connectivity_service.dart
â”‚   â””â”€â”€ config_service.dart
â””â”€â”€ widgets/
    â”œâ”€â”€ audio_recording_tile.dart
    â””â”€â”€ connectivity_status.dart
ğŸ”§ 2. Backend FastAPI (API Gateway)
Responsabilidades:
ğŸ“¥ RecepciÃ³n de archivos de audio

ğŸ” AutenticaciÃ³n y autorizaciÃ³n de usuarios

ğŸ”„ OrquestaciÃ³n de servicios internos

ğŸ“Š GestiÃ³n de metadatos y almacenamiento

ğŸ“¡ PublicaciÃ³n MQTT de eventos

ğŸ” Logging y monitoreo de operaciones

TecnologÃ­as:
Framework: FastAPI (Python 3.11+)

Async: asyncio, aiofiles

Database: Motor (async MongoDB driver)

MQTT: paho-mqtt

Auth: JWT tokens, bcrypt

Validation: Pydantic models

Estructura de APIs:


# Endpoints principales
POST /api/v1/auth/login
POST /api/v1/auth/register
POST /api/v1/audio/upload
GET  /api/v1/audio/history
GET  /api/v1/audio/{id}/transcription
POST /api/v1/webhooks/n8n
GET  /api/v1/health
ğŸ¯ 3. Servicio de TranscripciÃ³n (Whisper)
Responsabilidades:
ğŸµ ConversiÃ³n audio â†’ texto con alta precisiÃ³n

ğŸŒ Soporte multiidioma (espaÃ±ol prioritario)

âš¡ Procesamiento asÃ­ncrono de archivos

ğŸ“Š ExtracciÃ³n de metadatos de audio

ğŸ”§ OptimizaciÃ³n de modelos segÃºn recursos

ConfiguraciÃ³n:


# Modelos Whisper disponibles
WHISPER_MODELS = {
    "tiny": "39M params - RÃ¡pido, menor precisiÃ³n",
    "base": "74M params - Balanceado",
    "small": "244M params - Buena precisiÃ³n",
    "medium": "769M params - Alta precisiÃ³n",
    "large": "1550M params - MÃ¡xima precisiÃ³n"
}
# ConfiguraciÃ³n por defecto
DEFAULT_MODEL = "base"  # Para desarrollo
PRODUCTION_MODEL = "small"  # Para producciÃ³n
IntegraciÃ³n con OpenAI:


# Alternativa cloud para alta demanda
OPENAI_WHISPER_CONFIG = {
    "model": "whisper-1",
    "language": "es",
    "response_format": "json",
    "temperature": 0.0
}
ğŸ§  4. Procesador NLP (AnÃ¡lisis de Contenido)
Responsabilidades:
ğŸ“ ClasificaciÃ³n de contenido (personal/trabajo/ideas)

ğŸ˜Š AnÃ¡lisis de sentimiento y tono emocional

ğŸ¯ ExtracciÃ³n de entidades (fechas, tareas, personas)

ğŸ·ï¸ GeneraciÃ³n de etiquetas automÃ¡ticas

ğŸ” DetecciÃ³n de intenciones y acciones

Pipeline de Procesamiento:


class NLPPipeline:
    def process(self, transcription: str) -> ProcessedContent:
        # 1. Limpieza de texto
        clean_text = self.clean_text(transcription)
        # 2. AnÃ¡lisis de sentimiento
        sentiment = self.analyze_sentiment(clean_text)
        # 3. ClasificaciÃ³n de categorÃ­a
        category = self.classify_content(clean_text)
        # 4. ExtracciÃ³n de entidades
        entities = self.extract_entities(clean_text)
        # 5. DetecciÃ³n de acciones
        actions = self.detect_actions(clean_text)
        return ProcessedContent(
            text=clean_text,
            sentiment=sentiment,
            category=category,
            entities=entities,
            actions=actions
        )
ğŸ“Š 5. Base de Datos MongoDB
Esquemas de Datos:


// ColecciÃ³n: users
{
  "_id": ObjectId,
  "email": "user@example.com",
  "password_hash": "bcrypt_hash",
  "created_at": ISODate,
  "settings": {
    "language": "es",
    "auto_transcribe": true,
    "notification_preferences": {...}
  }
}
// ColecciÃ³n: recordings
{
  "_id": ObjectId,
  "user_id": ObjectId,
  "filename": "audio_20250705_123456.wav",
  "duration": 120.5,
  "transcription": "Texto transcrito...",
  "metadata": {
    "sentiment": "positive",
    "category": "work",
    "confidence": 0.95,
    "entities": [...],
    "actions": [...]
  },
  "status": "completed",
  "created_at": ISODate,
  "processed_at": ISODate
}
// ColecciÃ³n: automations
{
  "_id": ObjectId,
  "user_id": ObjectId,
  "recording_id": ObjectId,
  "workflow_id": "n8n_workflow_123",
  "actions_executed": [
    {
      "type": "jira_create_issue",
      "status": "success",
      "response": {...}
    }
  ],
  "created_at": ISODate
}
Ãndices Optimizados:


// Ãndices para performance
db.recordings.createIndex({"user_id": 1, "created_at": -1})
db.recordings.createIndex({"metadata.category": 1})
db.recordings.createIndex({"transcription": "text"})  // Full-text search
ğŸ“¡ 6. Broker MQTT (EMQX)
Estructura de Topics:


asistente/
â”œâ”€â”€ users/{user_id}/
â”‚   â”œâ”€â”€ notifications/        # Notificaciones generales
â”‚   â”œâ”€â”€ transcriptions/      # Resultados de transcripciÃ³n
â”‚   â”œâ”€â”€ automations/         # Estado de automatizaciones
â”‚   â””â”€â”€ system/              # Mensajes del sistema
â”œâ”€â”€ global/
â”‚   â”œâ”€â”€ announcements/       # Anuncios globales
â”‚   â””â”€â”€ maintenance/         # Mantenimiento del sistema
â””â”€â”€ integrations/
    â”œâ”€â”€ n8n/                 # Eventos de n8n
    â””â”€â”€ external/            # Servicios externos
ConfiguraciÃ³n de Seguridad:


# emqx.conf
authentication:
  - mechanism: password_based
    backend: mongodb
    collection: mqtt_users
authorization:
  - type: mongodb
    collection: mqtt_acl
ssl:
  enable: true
  certfile: /opt/emqx/etc/certs/cert.pem
  keyfile: /opt/emqx/etc/certs/key.pem
âš¡ 7. AutomatizaciÃ³n n8n
Workflows Principales:
ğŸ”„ Workflow 1: Procesamiento de Audio



{
  "name": "Audio Processing Pipeline",
  "nodes": [
    {
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "parameters": {
        "path": "audio-processed"
      }
    },
    {
      "name": "Content Classifier",
      "type": "n8n-nodes-base.function",
      "parameters": {
        "functionCode": "// LÃ³gica de clasificaciÃ³n"
      }
    },
    {
      "name": "Jira Integration",
      "type": "n8n-nodes-base.jira",
      "parameters": {
        "operation": "create",
        "resource": "issue"
      }
    },
    {
      "name": "MQTT Notification",
      "type": "n8n-nodes-base.mqtt",
      "parameters": {
        "topic": "asistente/users/{{$json.user_id}}/notifications"
      }
    }
  ]
}
ğŸ“… Workflow 2: GestiÃ³n de Calendario



{
  "name": "Calendar Management",
  "nodes": [
    {
      "name": "Date Extractor",
      "type": "n8n-nodes-base.function"
    },
    {
      "name": "Google Calendar",
      "type": "n8n-nodes-base.googleCalendar",
      "parameters": {
        "operation": "create",
        "resource": "event"
      }
    }
  ]
}
ğŸ” Seguridad y AutenticaciÃ³n
Flujo de AutenticaciÃ³n:


sequenceDiagram
    participant A as Flutter App
    participant B as FastAPI
    participant C as MongoDB
    A->>B: POST /auth/login (email, password)
    B->>C: Verify credentials
    C-->>B: User data
    B-->>A: JWT token + refresh token
    Note over A: Store tokens securely
    A->>B: API calls with Authorization header
    B->>B: Validate JWT
    B-->>A: Protected resource
Medidas de Seguridad Implementadas:
ğŸ”’ HTTPS/TLS en todas las comunicaciones

ğŸ”‘ JWT tokens con expiraciÃ³n automÃ¡tica

ğŸ›¡ï¸ Rate limiting en APIs crÃ­ticas

ğŸ” Cifrado de datos sensibles en MongoDB

ğŸ“ Logs de auditorÃ­a para acciones crÃ­ticas

ğŸš« ValidaciÃ³n de entrada con Pydantic

ğŸ“ˆ Escalabilidad y Performance
Estrategias de Escalado:
Horizontal Scaling:


# docker-compose.scale.yml
version: '3.8'
services:
  fastapi:
    deploy:
      replicas: 3
  whisper:
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
Caching Strategy:


# Redis para cache de transcripciones frecuentes
CACHE_CONFIG = {
    "redis_url": "redis://localhost:6379",
    "default_ttl": 3600,  # 1 hora
    "max_memory": "2gb"
}
Load Balancing:


# nginx.conf
upstream fastapi_backend {
    server fastapi_1:8000;
    server fastapi_2:8000;
    server fastapi_3:8000;
}
server {
    listen 80;
    location / {
        proxy_pass http://fastapi_backend;
    }
}
ğŸ”§ ConfiguraciÃ³n de Desarrollo
Docker Compose Setup:


version: '3.8'
services:
  app:
    build: ./audio_recorder_app
    ports:
      - "3000:3000"
    depends_on:
      - backend
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - MONGODB_URL=mongodb://mongo:27017
      - MQTT_BROKER=emqx:1883
    depends_on:
      - mongo
      - emqx
  mongo:
    image: mongo:7
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
  emqx:
    image: emqx/emqx:5
    ports:
      - "1883:1883"
      - "18083:18083"
  n8n:
    image: n8nio/n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
    volumes:
      - n8n_data:/home/node/.n8n
volumes:
  mongo_data:
  n8n_data:
ğŸ“Š Monitoreo y Observabilidad
MÃ©tricas Clave:
â±ï¸ Latencia de transcripciÃ³n por modelo

ğŸ“ˆ Throughput de requests por segundo

ğŸ’¾ Uso de memoria en servicios Whisper

ğŸ“¡ Conexiones MQTT activas

ğŸ”„ Tasa de Ã©xito de automatizaciones

Logging Structure:


{
  "timestamp": "2025-07-05T18:30:00Z",
  "level": "INFO",
  "service": "fastapi",
  "user_id": "user_123",
  "action": "audio_upload",
  "duration_ms": 1250,
  "file_size_mb": 2.3,
  "status": "success"
}
ğŸš€ PrÃ³ximos Pasos TÃ©cnicos
Sprint 1 - ImplementaciÃ³n Core:
âœ… Setup completo de Docker Compose

âœ… API bÃ¡sica de upload de audio

âœ… IntegraciÃ³n Whisper local

âœ… Cliente MQTT en Flutter

âœ… Workflow n8n bÃ¡sico

Sprint 2 - OptimizaciÃ³n:
ğŸ”„ Caching con Redis

ğŸ”„ Rate limiting avanzado

ğŸ”„ Monitoreo con Prometheus

ğŸ”„ CI/CD pipeline

Sprint 3+ - Escalabilidad:
ğŸ“ˆ Kubernetes deployment

ğŸ“ˆ Auto-scaling de servicios

ğŸ“ˆ Multi-region setup

ğŸ“ˆ Advanced analytics

DocumentaciÃ³n tÃ©cnica actualizada: Julio 5, 2025